{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v3xlrm1nOwo1/Songs-Genre-Classification-by-Lyrics-With-BERT-And-LoRA/blob/main/Songs_Genre_Classification_by_Lyrics_With_BERT_And_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlNlQQfgaedP"
      },
      "source": [
        "#**Music Genre Classification by Lyrics With BERT**\n",
        "\n",
        "> BERT\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41FUJI8Oaeay"
      },
      "source": [
        "## *Download Dataset and Lyary*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfAhg39F1s72"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MT8U92e_e3kz"
      },
      "outputs": [],
      "source": [
        "!mkdir ../root/.kaggle\n",
        "!mv kaggle.json ../root/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxo9J2UJ1_52"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d neisse/scrapped-lyrics-from-6-genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BuwwFOHELfT"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DFla67CAEsaA"
      },
      "outputs": [],
      "source": [
        "! mkdir music_genre_classification_by_lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLCmS1g-E_nI"
      },
      "outputs": [],
      "source": [
        "! unzip scrapped-lyrics-from-6-genres.zip -d music_genre_classification_by_lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeAc5j7qFLkd"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOR-3YKCFPtm"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/thunlp/OpenDelta.git"
      ],
      "metadata": {
        "id": "ZhtL33rQ0BdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4idnj0VxFkaa"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import libraris\n",
        "\n"
      ],
      "metadata": {
        "id": "DKkflRPtTyHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ph9hJENLFoWx"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import opendelta\n",
        "\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "from pylab import rcParams\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textwrap import wrap\n",
        "from collections import defaultdict\n",
        "from accelerate import Accelerator\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaiyC9ncFve2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 10, 4\n",
        "\n",
        "RANDOM_SEED = 666\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "LEARN_RATE = 3e-6\n",
        "RANDOM_SEED = 666\n",
        "MAX_LEN = 300\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 3\n",
        "CHECKPOINT= 'bert-base-cased'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read and Preprocessing Data"
      ],
      "metadata": {
        "id": "6WyKw74VCc0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGqsRVEsGAIJ"
      },
      "outputs": [],
      "source": [
        "artists_df = pd.read_csv('music_genre_classification_by_lyrics/artists-data.csv')\n",
        "\n",
        "artists_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghw36T70RQ9q"
      },
      "outputs": [],
      "source": [
        "artists_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0Vq7MlFzrVO"
      },
      "outputs": [],
      "source": [
        "len(artists_df.Genres.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pio07XILwYoB"
      },
      "outputs": [],
      "source": [
        "artists_df.rename(columns={'Genres':'Genre'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyntTHFpGRti"
      },
      "outputs": [],
      "source": [
        "lyrics_df = pd.read_csv('music_genre_classification_by_lyrics/lyrics-data.csv')\n",
        "\n",
        "lyrics_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XfRGlJ5Gw_4"
      },
      "outputs": [],
      "source": [
        "lyrics_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qwMebMn0Mof"
      },
      "outputs": [],
      "source": [
        "len(lyrics_df.Lyric.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_clR-KERwWb"
      },
      "outputs": [],
      "source": [
        "artists_df = artists_df.drop_duplicates(subset = 'Link', keep ='first')\n",
        "\n",
        "lyrics_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ojmRDIkHRwUZ"
      },
      "outputs": [],
      "source": [
        "lyrics_df.rename(columns={'ALink':'Link'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AIrEYo88SXfQ"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df = pd.merge(lyrics_df ,artists_df, on='Link')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ1jmvAyS1EA"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9ePS4myS-ip"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhOxR1c6S7bS"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLLqXR3GIwma"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df.language.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiVh4JUeI-kl"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df.groupby('language')['Lyric'].count().sort_values(ascending=[0])[: 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWAYm3j9GXcP"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df = lyrics_artists_df[lyrics_artists_df['language'] == 'en']\n",
        "\n",
        "lyrics_artists_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnO_AZPv12-H"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BPp596gzTzQB"
      },
      "outputs": [],
      "source": [
        "lyrics_artists_df = lyrics_artists_df[['Lyric', 'Genre', 'Artist', 'Popularity', 'SName']]\n",
        "df = lyrics_artists_df[lyrics_artists_df.Lyric.notnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmwqE20Ucspl"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs-UleX4c0pn"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8eAcYPSP2tT"
      },
      "outputs": [],
      "source": [
        "artists = lyrics_artists_df['Artist'].unique()\n",
        "genres = lyrics_artists_df['Genre'].unique()\n",
        "\n",
        "len(genres)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtmPHKsqbM1X"
      },
      "outputs": [],
      "source": [
        "df.groupby('Genre')['Lyric'].count().sort_values(ascending=[0])[: 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plgudts27EmV"
      },
      "outputs": [],
      "source": [
        "'Rap; Hip Hop; Black Musi'.find('Rap')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAAis_K0d9hy"
      },
      "outputs": [],
      "source": [
        "all_ge = {'Rock': 0, 'Hip Hop': 0, 'Pop': 0}\n",
        "\n",
        "for g in df['Genre']:\n",
        "    if str(g).find('Hip Hop') != -1:\n",
        "        all_ge['Hip Hop'] = all_ge['Hip Hop'] + 1\n",
        "\n",
        "\n",
        "for g in df['Genre']:\n",
        "    if str(g).find('Rock') != -1:\n",
        "        all_ge['Rock'] = all_ge['Rock'] + 1\n",
        "\n",
        "\n",
        "for g in df['Genre']:\n",
        "    if str(g).find('Pop') != -1:\n",
        "        all_ge['Pop'] = all_ge['Pop'] + 1\n",
        "\n",
        "print(all_ge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXH_8vRL9Gkz"
      },
      "outputs": [],
      "source": [
        "ge = {'Rock / pop': 0, 'Hip Hop / pop': 0, 'Rock / Hip Hop': 0}\n",
        "\n",
        "for g in df['Genre']:\n",
        "    if str(g).find('Hip Hop') != -1 and str(g).find('Rock') != -1:\n",
        "        ge['Rock / Hip Hop'] = ge['Rock / Hip Hop'] + 1\n",
        "\n",
        "for g in df['Genre']:\n",
        "    if str(g).find('Rock') != -1 and str(g).find('Pop') != -1:\n",
        "        ge['Rock / pop'] = ge['Rock / pop'] + 1\n",
        "\n",
        "for g in df['Genre']:\n",
        "    if str(g).find('Pop') != -1 and str(g).find('Hip Hop') != -1:\n",
        "        ge['Hip Hop / pop'] = ge['Hip Hop / pop'] + 1\n",
        "\n",
        "print(ge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtaFrI8P_KPt"
      },
      "outputs": [],
      "source": [
        "most_HipHop = all_ge['Hip Hop'] - ge['Hip Hop / pop'] - ge['Rock / Hip Hop']\n",
        "most_pop = all_ge['Pop'] - ge['Hip Hop / pop'] - ge['Rock / pop']\n",
        "most_rock = all_ge['Rock'] - ge['Rock / Hip Hop'] - ge['Rock / pop']\n",
        "\n",
        "hip_hop = all_ge['Hip Hop']\n",
        "pop = all_ge['Pop']\n",
        "rock = all_ge['Rock']\n",
        "\n",
        "mf_HipHop = all_ge['Hip Hop']\n",
        "mf_pop = all_ge['Pop'] - ge['Hip Hop / pop']\n",
        "mf_rock = all_ge['Rock'] - ge['Rock / Hip Hop'] - ge['Rock / pop']\n",
        "\n",
        "print(f'All    ==> Hip Hop: {hip_hop} - Pop: {pop} - Rock: {rock}')\n",
        "print(f'Some   ==> Hip Hop: {most_HipHop} - Pop: {most_pop} - Rock: {most_rock}')\n",
        "print(f'Modify ==> Hip Hop: {mf_HipHop} - Pop: {mf_pop} - Rock: {mf_rock}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSUmHlvMrlnA"
      },
      "outputs": [],
      "source": [
        "94992 - 32262 - 874"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "XxcQI6d_JHFT"
      },
      "outputs": [],
      "source": [
        "df['Rock'] = df['Genre'].apply(func = (lambda genre: 1 if str(genre).find('Rock') != -1 else 0 ))\n",
        "df['Hip Hop'] = df['Genre'].apply(func = (lambda genre: 1 if str(genre).find('Hip Hop') != -1 else 0 ))\n",
        "df['Pop'] = df['Genre'].apply(func = (lambda genre: 1 if str(genre).find('Pop') != -1 else 0 ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ihuvfzbSF2K"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPd9Mag44Q9i"
      },
      "outputs": [],
      "source": [
        "df['Hip Hop'].sum(), df['Pop'].sum(), df['Rock'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sqOhZPpbh2f6"
      },
      "outputs": [],
      "source": [
        "LABEL_COLUMNS = ['Pop', 'Hip Hop', 'Rock']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smap1uh6hyWO"
      },
      "outputs": [],
      "source": [
        "df[LABEL_COLUMNS].sum().sort_values().plot(kind='bar');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE7JJcTZ4Q7N"
      },
      "outputs": [],
      "source": [
        "song = str(df.iloc[0, 0])\n",
        "\n",
        "print(song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPyMJqfzw6jO"
      },
      "outputs": [],
      "source": [
        "' '.join(song.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ForjrqW5XA7B"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhikQWf4UT0J"
      },
      "outputs": [],
      "source": [
        "df[(df['Rock'] == 0) & (df['Hip Hop'] == 0) & (df['Pop'] == 0)]['Genre'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpEUhXKYmD6m"
      },
      "outputs": [],
      "source": [
        "dataset_df = df[(df['Rock'] == 1) | (df['Hip Hop'] == 1) | (df['Pop'] == 1)]\n",
        "\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yohHUVCH0Quc"
      },
      "outputs": [],
      "source": [
        "dataset_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JltIBmmq0Vhm"
      },
      "outputs": [],
      "source": [
        "dataset_df['Hip Hop'].sum(), dataset_df['Pop'].sum(), dataset_df['Rock'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-3vIAm0iS0b"
      },
      "outputs": [],
      "source": [
        "dataset_df['Rock'] = dataset_df.apply(func = (lambda df: 0 if (df['Rock'] == 1 and df['Hip Hop'] == 1) else df['Rock']), axis=1)\n",
        "dataset_df['Rock'] = dataset_df.apply(func = (lambda df: 0 if (df['Rock'] == 1 and df['Pop'] == 1) else df['Rock']), axis=1)\n",
        "\n",
        "dataset_df['Pop'] = dataset_df.apply(func = (lambda df: 0 if  (df['Pop'] == 1 and df['Hip Hop'] == 1) else df['Pop']), axis=1)\n",
        "\n",
        "\n",
        "print(f'All    ==> Hip Hop: {hip_hop} - Pop: {pop} - Rock: {rock}')\n",
        "print(f'Some   ==> Hip Hop: {most_HipHop} - Pop: {most_pop} - Rock: {most_rock}')\n",
        "print(f'Modify ==> Hip Hop: {mf_HipHop} - Pop: {mf_pop} - Rock: {mf_rock}')\n",
        "\n",
        "dataset_df['Hip Hop'].sum(), dataset_df['Pop'].sum(), dataset_df['Rock'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqLp9MoSyOh7"
      },
      "outputs": [],
      "source": [
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9Zc9em1yTjd"
      },
      "outputs": [],
      "source": [
        "dataset_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "DxgG1FEaC_qm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjglW9z50F5-"
      },
      "outputs": [],
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-uyjGi4z9Uk"
      },
      "outputs": [],
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in dataset_df.Lyric:\n",
        "  tokens = tokenizer.encode(txt)\n",
        "  token_lens.append(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boJO0-7h0PkM"
      },
      "outputs": [],
      "source": [
        "sns.distplot(token_lens, hist=True)\n",
        "plt.xlim([0, 512]);\n",
        "plt.xlabel('Token count');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql0Exu0xgowF"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(dataset_df, test_size=0.1, random_state=RANDOM_SEED)\n",
        "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=RANDOM_SEED)\n",
        "\n",
        "train_df.shape, val_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfZhVqwfzOTL"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo_v9chy2QbA"
      },
      "outputs": [],
      "source": [
        "train_df['Hip Hop'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePv1Hnijw6gu"
      },
      "outputs": [],
      "source": [
        "labes = dataset_df.iloc[0, 5:]\n",
        "labes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plwadzicxJzR"
      },
      "outputs": [],
      "source": [
        "labes.values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoder"
      ],
      "metadata": {
        "id": "iXFAAlRiDGg_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "sEa3Eda9drOd"
      },
      "outputs": [],
      "source": [
        "class LyricDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data: pd.DataFrame, tokenizer: transformers.BertTokenizer, max_len: int = 512, include_row_text=False):\n",
        "    self.data = data\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.include_row_text = include_row_text\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    data_row = self.data.iloc[item]\n",
        "\n",
        "    lyric_text = str(data_row.Lyric)\n",
        "    lyric_text = ' '.join(lyric_text.split())\n",
        "    labels = data_row[self.data.columns.tolist()[5: ]]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        lyric_text,\n",
        "        add_special_tokens=True,\n",
        "        return_token_type_ids=False,\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        max_length=self.max_len,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "\n",
        "    output =  {\n",
        "        'input_ids': encoding['input_ids'].flatten(),\n",
        "        'attention_mask': encoding['attention_mask'].flatten(),\n",
        "        'labels': torch.FloatTensor(labels)\n",
        "    }\n",
        "\n",
        "    if self.include_row_text:\n",
        "        output['lyric_text'] = lyric_text\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "OsCEzu8D4-ks"
      },
      "outputs": [],
      "source": [
        "def create_data_loader(df, tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE, include_row_text=False, shuffle=False):\n",
        "  ds = LyricDataset(\n",
        "    data=df,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len,\n",
        "    include_row_text=include_row_text\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    shuffle=shuffle,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkuzPcul6Rj4"
      },
      "outputs": [],
      "source": [
        "train_data_loader = create_data_loader(df=train_df, tokenizer=tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_data_loader = create_data_loader(df=val_df, tokenizer=tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_data_loader = create_data_loader(df=test_df, tokenizer=tokenizer, max_len=MAX_LEN, batch_size=BATCH_SIZE, include_row_text=True, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI2SbO6j6dAl"
      },
      "outputs": [],
      "source": [
        "data = next(iter(test_data_loader))\n",
        "data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVG0xC436tWJ"
      },
      "outputs": [],
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['labels'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "laENfC6PDXaH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "7P-242qv7B0m"
      },
      "outputs": [],
      "source": [
        "class MusicGenreClassification(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes: int = 3):\n",
        "    super(MusicGenreClassification, self).__init__()\n",
        "    self.bert = transformers.BertModel.from_pretrained(CHECKPOINT, return_dict=True)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "    self.linear = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, return_dict=True):\n",
        "    output = self.bert(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask\n",
        "        )\n",
        "    output = self.linear(output.pooler_output)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "KRap6KCA8nWM"
      },
      "outputs": [],
      "source": [
        "model = MusicGenreClassification(n_classes=3)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter Efficient FineTuning"
      ],
      "metadata": {
        "id": "SRaBs86yDbHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delta_model = opendelta.AdapterModel(model)\n",
        "delta_model = opendelta.LoraModel(model)\n",
        "delta_model.freeze_module(exclude=[\"deltas\", \"classifier\"]) # leave the delta tuning modules and the newly initialized classification head tunable.\n",
        "delta_model.log() # optional: to visualize how the `model` changes."
      ],
      "metadata": {
        "id": "WneNbbhN_IOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cro9i2gu8sBV"
      },
      "outputs": [],
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTXekpLF81G3"
      },
      "outputs": [],
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Functions"
      ],
      "metadata": {
        "id": "fEX6HzOCDyv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, labels):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, labels).to(device)"
      ],
      "metadata": {
        "id": "JDencbDyCoem"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coumpute_accuracy(predictions, labels, threshold=0.5):\n",
        "  binray_predictions = (predictions > 0.5).double()\n",
        "  pre_label_accuracy = (binray_predictions == labels).double().mean(dim=0)\n",
        "\n",
        "  rock, hip_hop, pop = pre_label_accuracy\n",
        "  average_accuracy = pre_label_accuracy.mean()\n",
        "\n",
        "  return average_accuracy.double(), rock.double(), hip_hop.double(), pop.double()"
      ],
      "metadata": {
        "id": "pwI5W6WpY_N9"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSt5PmbF92QU"
      },
      "outputs": [],
      "source": [
        "optimizer = transformers.AdamW(model.parameters(), lr=LEARN_RATE, correct_bias=False)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "YnzDvqqsD3NR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "3e-yeX8o93xs"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, scheduler, n_examples, device):\n",
        "    model = model.train()\n",
        "\n",
        "    losses = []\n",
        "    average_accuracy, rock, hip_hop, pop = (0, 0, 0, 0)\n",
        "\n",
        "    for index, batch in enumerate(data_loader):\n",
        "        input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
        "        attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
        "        labels = batch['labels'].to(device, dtype=torch.float)\n",
        "\n",
        "        outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "       )\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        average_accuracy_, rock_, hip_hop_, pop_ = coumpute_accuracy(torch.softmax(outputs, dim=1), labels)\n",
        "\n",
        "        average_accuracy += average_accuracy_.item()\n",
        "        rock += rock_.item()\n",
        "        hip_hop += hip_hop_.item()\n",
        "        pop += pop_.item()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    return {'Average Accuracy': average_accuracy, 'Rock': rock, 'Pop': pop, 'Hip Hop': hip_hop} , np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "0T2z6Fc0BNNh"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "\n",
        "    losses = []\n",
        "    average_accuracy, rock, hip_hop, pop = (0, 0, 0, 0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for index, batch in enumerate(data_loader):\n",
        "            input_ids = batch[\"input_ids\"].to(device, dtype=torch.long)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n",
        "            labels = batch[\"labels\"].to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            average_accuracy_, rock_, hip_hop_, pop_ = coumpute_accuracy(torch.softmax(outputs, dim=1), labels)\n",
        "\n",
        "            average_accuracy += average_accuracy_.item()\n",
        "            rock += rock_.item()\n",
        "            hip_hop += hip_hop_.item()\n",
        "            pop += pop_.item()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            return {'Average Accuracy': average_accuracy, 'Rock': rock, 'Pop': pop, 'Hip Hop': hip_hop} , np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHKPLpUxBTqk"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print('=' * 50)\n",
        "    print(f'Epoch {epoch + 1} / {EPOCHS}')\n",
        "\n",
        "    train_acc, train_loss = train_epoch(model=model, data_loader=train_data_loader, loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler, n_examples=len(train_df), device=device)\n",
        "    print(f'Train loss {train_loss}, accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(model=model, data_loader=val_data_loader, loss_fn=loss_fn, device=device, n_examples=len(val_df))\n",
        "    print(f'Val loss {val_loss}, accuracy {val_acc}')\n",
        "\n",
        "    print('=' * 50)\n",
        "\n",
        "    history['train_acc'].append(train_acc['Average Accuracy'])\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc['Average Accuracy'])\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "\n",
        "    if val_acc['Average Accuracy'] > best_accuracy:\n",
        "        # torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "        delta_model.save_finetuned('bert_model_state')\n",
        "        best_accuracy = val_acc['Average Accuracy']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPatXvawoKUkxovOXL4DUsR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}